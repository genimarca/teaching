{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En este cuaderno se muestran algunos ejemplos del nivel de prosamiento de Tokenización y Segmentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga de datos desde el proyecto Gutenberg, en concreto el Quijote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "URL_LIBRO = \"http://www.gutenberg.org/cache/epub/2000/pg2000.txt\"\n",
    "file_book = request.urlopen(URL_LIBRO)\n",
    "raw_book = file_book.read().decode(\"utf-8\")\n",
    "print(raw_book[500:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de segmentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "sents_book = sent_tokenize(raw_book, language=\"spanish\")\n",
    "print(\"5 oraciones del libro descargado: %s\" % \"\\n\".join(sents_book[500:505]))\n",
    "n_sents = len(sents_book)\n",
    "print(\"\\nNº. de oraciones: %d\" % n_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de Tokanización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "sent_tokens = [tokenizer.tokenize(sent) for sent in sents_book]\n",
    "print(\"Tokens de 5 oraciones: %s\" % \"\\n\".join(map(lambda x:\", \".join(x), sent_tokens[500:505])))\n",
    "n_words = 0\n",
    "for sent in sents_book:\n",
    "    n_words += len(sent)\n",
    "print(\"\\nNº. de palabras: %d\" % n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo de la bolsa de palabras (hay palabras repetidas). Se suelen pasar todas a minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = [word.lower() for sent in sent_tokens for word in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de función de cálculo y exposición de frecuencias en términos absolutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "def calculo_frecuencias(bag_of_words):\n",
    "    \"\"\"Calcula frecuencias de las palabras y muestra una gráfica con las más frecuentes\n",
    "    \n",
    "    Args:\n",
    "        bag_of_words: lista de strings\n",
    "    \"\"\"\n",
    "    freq_dist = FreqDist(bag_of_words)\n",
    "    print(\"Nº. objetos: %d\"%freq_dist.N())\n",
    "    print(\"Nº. objetos únicos: %d\"%freq_dist.B())\n",
    "    print(\"El objeto más frecuente es: %s\" % str(freq_dist.max()))\n",
    "    freq_dist.plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Frecuencias\\n\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "calculo_frecuencias(bag_of_words)\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La palabras frecuentes son signos de puntuación y palabras vacías, veamos que ocurre si las quitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def rm_puntuation(bag_of_words):\n",
    "    \"\"\"Elimina los signos de puntuación.\n",
    "    \n",
    "    Args:\n",
    "        bag_of_words: lista de strings.\n",
    "        \n",
    "    \"\"\"\n",
    "    re_puntuation = re.compile(r\"\"\"[\\.,\":;]\"\"\")\n",
    "    bag_of_words_no_puntation = [word for word in bag_of_words if re_puntuation.fullmatch(word) is None]\n",
    "    return bag_of_words_no_puntation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No signos de puntuación\\n\")\n",
    "bag_of_words_no_puntuacion = rm_puntuation(bag_of_words)\n",
    "plt.figure(figsize=(20, 10))\n",
    "calculo_frecuencias(bag_of_words_no_puntuacion)\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def rm_stopwods(bag_of_words):\n",
    "    \"\"\"Elimina las stopwords del texto de entrada\n",
    "    \n",
    "    Args:\n",
    "        sent_words_book: lista de strings.\n",
    "    \n",
    "    Returns:\n",
    "        Una lista de listas de oraciones por palabras sin incluir las \n",
    "        palabras vacías.\n",
    "    \"\"\"\n",
    "    spanish_stopwords = stopwords.words(\"spanish\")\n",
    "    no_stop_words = [word for word in bag_of_words if word not in spanish_stopwords]\n",
    "    return no_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stopper\\n\")\n",
    "bag_of_words_no_puntuacion_no_stopper = rm_stopwods(bag_of_words_no_puntuacion)\n",
    "plt.figure(figsize=(20, 10))\n",
    "calculo_frecuencias(bag_of_words_no_puntuacion_no_stopper)\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos lo que ocurre con Bigramas y Trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "print(\"Unigramas/Bigramas/Trigramas\\n\")\n",
    "    \n",
    "print(\"Unigramas: %s\" % \", \".join(bag_of_words_no_puntuacion_no_stopper[500:510]))\n",
    "print(\"---------------------------\")\n",
    "print(\"-Bigramas\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "bag_of_bigrams = list(bigrams(bag_of_words_no_puntuacion_no_stopper))\n",
    "calculo_frecuencias(bag_of_bigrams)\n",
    "print(\"---------------------------\")\n",
    "print(\"-Trigramas\")\n",
    "bag_of_trigrams = trigrams(bag_of_words_no_puntuacion_no_stopper)\n",
    "plt.figure(figsize=(20, 10))\n",
    "calculo_frecuencias(bag_of_trigrams)\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
